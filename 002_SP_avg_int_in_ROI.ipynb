{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import napari\n",
    "import nd2\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from utils import get_gpu_details, list_images, read_image\n",
    "\n",
    "get_gpu_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the path where your images are stored, you can use absolute or relative paths to point at other disk locations\n",
    "directory_path = Path(\"./raw_data/nihanseb_organoid\")\n",
    "\n",
    "# Image size reduction (downsampling) to improve processing times (slicing, not lossless compression)\n",
    "# Now, in addition to xy, you can downsample across your z-stack\n",
    "slicing_factor_xy = 4 # Use 2 or 4 for downsampling in xy (None for lossless)\n",
    "slicing_factor_z = None # Use 2 to select 1 out of every 2 z-slices\n",
    "\n",
    "# Define the nuclei and markers of interest channel order ('Remember in Python one starts counting from zero')\n",
    "nuclei_channel = 2\n",
    "\n",
    "# Define the channels you want to analyze using the following structure:\n",
    "# markers = [(channel_name, channel_nr),(..., ...)]\n",
    "# Remember in Python one starts counting from 0, so your first channel will be 0\n",
    "# i.e. markers = [(\"ARSA\", 0), (\"MBP\", 1)]\n",
    "markers = [(\"ARSA\", 0), (\"MBP\", 1)]\n",
    "\n",
    "# Fill holes inside the resulting organoid mask? Set to False if you want to keep the holes\n",
    "fill_holes = True\n",
    "\n",
    "# Analyze intensity within the 3D volume of the ROI, or perform a mean or max intensity projection of the marker channel (2D)\n",
    "analysis_type = \"2D\" #\"2D\" or \"3D\"\n",
    "\n",
    "# If 2D analysis type, Choose projection type (mean intensity or max intensity)\n",
    "# Mean intensity projection would be the equivalent of analyzing avg_intensity within the 3D volume\n",
    "projection_type = \"mean\" # \"mean\" or \"max\"\n",
    "\n",
    "# Stardist model name if nuclei labels predictions are present\n",
    "model_name = None\n",
    "\n",
    "# Iterate through the .czi and .nd2 files in the raw_data directory\n",
    "images = list_images(directory_path)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore each image to analyze (0 defines the first image in the directory)\n",
    "image = images[0]\n",
    "\n",
    "# Read image, apply slicing if needed and return filename and img as a np array\n",
    "img, filename = read_image(image, slicing_factor_xy, slicing_factor_z)\n",
    "\n",
    "# Generate maximum or mean intensity projection\n",
    "if projection_type == \"max\":\n",
    "    img_projection = np.max(img, axis=1)\n",
    "elif projection_type == \"mean\":\n",
    "    img_projection = np.mean(img, axis=1)\n",
    "\n",
    "# Show image in Napari\n",
    "viewer = napari.Viewer(ndisplay=2)\n",
    "viewer.add_image(img_projection, name=f\"{projection_type}_projection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct ROI and nuclei predictions paths from directory_path above\n",
    "roi_path = directory_path / \"ROIs\"\n",
    "# nuclei_preds_path =  directory_path / \"nuclei_preds\" / analysis_type / model_name\n",
    "\n",
    "# Extract the experiment name from the data directory path\n",
    "experiment_id = directory_path.name\n",
    "\n",
    "# Check for presence of ROIs\n",
    "try:\n",
    "    roi_names = [folder.name for folder in roi_path.iterdir() if folder.is_dir()]\n",
    "\n",
    "except FileNotFoundError:\n",
    "    roi_names = [\"auto_generated_ROI\"]\n",
    "    print(\"No manually defined ROI found, generating ROI automatically...\")\n",
    "\n",
    "# Create a 'results' folder in the root directory to store results\n",
    "results_folder = Path(\"results\") / experiment_id\n",
    "\n",
    "try:\n",
    "    os.makedirs(results_folder)\n",
    "    print(f\"'{results_folder}' folder created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"'{results_folder}' folder already exists.\")\n",
    "\n",
    "# Add the 3D-stack into Napari\n",
    "if analysis_type == \"3D\":\n",
    "    # Remove the 'img_mip' layer if it exists\n",
    "    if f\"{projection_type}_projection\" in viewer.layers:\n",
    "        viewer.layers.remove(f\"{projection_type}_projection\")\n",
    "    # Add the 'img' stack\n",
    "    viewer.add_image(img)\n",
    "    # Set projection_type variable to None\n",
    "    projection_type = None\n",
    "\n",
    "for roi_name in roi_names:\n",
    "\n",
    "    print(f\"\\nAnalyzing ROI: {roi_name}\")\n",
    "\n",
    "    # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "    props_list = []\n",
    "\n",
    "    # Read the user defined ROIs, in case of missing ROI implement logic for automatic segmentation\n",
    "    try:\n",
    "        # Read previously defined ROIs\n",
    "        organoid_mask = tifffile.imread(roi_path / roi_name / f\"{filename}.tiff\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Add logic to automatically generate an organoid mask\n",
    "        pass\n",
    "\n",
    "    # Resample the organoid ROI if input img and ROI shape differ\n",
    "    if organoid_mask.shape[-2:] != img.shape[-2:]:\n",
    "        roi_slicing_factor = round(organoid_mask.shape[-1] / img.shape[-1])\n",
    "        \n",
    "        if roi_slicing_factor > 1:\n",
    "            print(\"Slicing ROI to match input image shape\")\n",
    "            organoid_mask = organoid_mask[::round(roi_slicing_factor), ::round(roi_slicing_factor)]\n",
    "    \n",
    "        elif roi_slicing_factor < 1:\n",
    "            print(\"Upsampling ROI to match input image shape\")\n",
    "            organoid_mask = resize(\n",
    "                organoid_mask, img.shape[-2:], order=0, preserve_range=True, anti_aliasing=False\n",
    "            )\n",
    "\n",
    "    # If analysis type == \"3D\" extend ROI over the entire volume\n",
    "    if analysis_type == \"3D\":\n",
    "        # Extract the number of z-slices to extend the mask\n",
    "        slice_nr = img.shape[1]\n",
    "        # Extend the mask across the entire volume\n",
    "        organoid_mask = np.tile(organoid_mask, (slice_nr, 1, 1))\n",
    "        \n",
    "    # Show organoid ROI over input image \n",
    "    viewer.add_labels(organoid_mask)\n",
    "\n",
    "    if fill_holes:\n",
    "        # Close empty holes surrounded by True pixels\n",
    "        organoid_mask = binary_fill_holes(organoid_mask)\n",
    "        viewer.add_labels(organoid_mask, name=\"closed_organoids_mask\")\n",
    "\n",
    "    # Transform organoid mask into a label type without the need to perform connected components\n",
    "    organoid_mask = organoid_mask.astype(np.uint8)\n",
    "\n",
    "    # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "    props_list = []\n",
    "\n",
    "    # Create a dictionary containing all image descriptors\n",
    "    descriptor_dict = {\n",
    "                \"filename\": filename,\n",
    "                \"roi\": roi_name,\n",
    "                \"fill_holes\": fill_holes,\n",
    "                \"slicing_factor_xy\": slicing_factor_xy,\n",
    "                \"analysis_type\": analysis_type,\n",
    "                \"projection_type\": projection_type,\n",
    "                }\n",
    "\n",
    "    for channel_name, ch_nr in markers:\n",
    "\n",
    "        if analysis_type == \"2D\":\n",
    "            # Extract intensity information from each marker channel\n",
    "            props = measure.regionprops_table(label_image=organoid_mask,\n",
    "                                    intensity_image=img_projection[ch_nr],\n",
    "                                    properties=[\"label\", \"area\", \"intensity_mean\"])\n",
    "            \n",
    "        elif analysis_type == \"3D\":\n",
    "            # Extract intensity information from each marker channel\n",
    "            props = measure.regionprops_table(label_image=organoid_mask,\n",
    "                                    intensity_image=img[ch_nr],\n",
    "                                    properties=[\"label\", \"area\", \"intensity_mean\"])\n",
    "            \n",
    "        print(f\"Extracting avg_int for {channel_name} inside {analysis_type}_{roi_name}\")\n",
    "        \n",
    "        # Convert to dataframe\n",
    "        props_df = pd.DataFrame(props)\n",
    "\n",
    "        # Rename intensity_mean column to indicate the specific image\n",
    "        props_df.rename(columns={\"intensity_mean\": f\"{channel_name}_avg_int\"}, inplace=True)\n",
    "\n",
    "        # Append each props_df to props_list\n",
    "        props_list.append(props_df)\n",
    "\n",
    "    # Initialize the df with the first df in the list\n",
    "    props_df = props_list[0]\n",
    "    # Start looping from the second df in the list\n",
    "    for df in props_list[1:]:\n",
    "        props_df = props_df.merge(df, on=(\"label\",\"area\"))\n",
    "\n",
    "    # Add each key-value pair from descriptor_dict to props_df at the specified position\n",
    "    insertion_position = 0    \n",
    "    for key, value in descriptor_dict.items():\n",
    "        props_df.insert(insertion_position, key, value)\n",
    "        insertion_position += 1  # Increment position to maintain the order of keys in descriptor_dict\n",
    "\n",
    "    # Sort by area in descending order\n",
    "    props_df = props_df.sort_values(by='area', ascending=False)\n",
    "\n",
    "    # Define the .csv path\n",
    "    csv_path = results_folder / f'{filename}_per_label_avg_int.csv'\n",
    "\n",
    "    # Append to the .csv with new data points each round\n",
    "    props_df.to_csv(csv_path, mode=\"a\", index=False, header=not os.path.isfile(csv_path))\n",
    "\n",
    "# Show the updated .csv \n",
    "csv_df = pd.read_csv(csv_path)\n",
    "\n",
    "csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nd2.ND2File(image) as nd2_data:\n",
    "    # Get the first channel's volume metadata\n",
    "    first_channel = nd2_data.metadata.channels[0]\n",
    "    voxel_size = first_channel.volume.axesCalibration  # X, Y, Z calibration\n",
    "\n",
    "    # Extract pixel sizes\n",
    "    pixel_size_x, pixel_size_y, voxel_size_z = voxel_size\n",
    "\n",
    "    print(f\"Pixel size: {pixel_size_x:.3f} µm x {pixel_size_y:.3f} µm\")\n",
    "    print(f\"Voxel (Z-step) size: {voxel_size_z:.3f} µm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
