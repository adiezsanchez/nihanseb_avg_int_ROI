{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: /device:GPU:0\n",
      "Device type: GPU\n",
      "GPU model: device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from utils import get_gpu_details, list_images, read_image\n",
    "\n",
    "get_gpu_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_data\\\\nihanseb_organoid\\\\MLD 1.8 block11 slide3 ARSA MBP batch 2 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 1.8 block4 ARSA MBP batch 1 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 2.2 block2 ARSA MBP batch 1 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 2.2 block7 ARSA MBP batch 2 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 3.5 block2 ARSA MBP batch 2 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 5.2 block2 ARSA MBP batch 1 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 5.2 block4 ARSA MBP batch 2 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 6.3 block7 ARSA MBP batch 2 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 7.5 block13 ARSA MBP batch 1 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 7.5 block14 ARSA MBP batch 2 40x.nd2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the path where your images are stored, you can use absolute or relative paths to point at other disk locations\n",
    "directory_path = Path(\"./raw_data/nihanseb_organoid\")\n",
    "\n",
    "# Image size reduction (downsampling) to improve processing times (slicing, not lossless compression)\n",
    "# Now, in addition to xy, you can downsample across your z-stack\n",
    "slicing_factor_xy = 2 # Use 2 or 4 for downsampling in xy (None for lossless)\n",
    "slicing_factor_z = None # Use 2 to select 1 out of every 2 z-slices\n",
    "\n",
    "# Define the nuclei and markers of interest channel order ('Remember in Python one starts counting from zero')\n",
    "nuclei_channel = 2\n",
    "\n",
    "# Fill holes inside the resulting organoid mask? Set to False if you want to keep the holes\n",
    "fill_holes = True\n",
    "\n",
    "# Analyze intensity within the 3D volume of the ROI, or perform a mean or max intensity projection of the marker channel (2D)\n",
    "analysis_type = \"2D\" #\"2D\" or \"3D\"\n",
    "\n",
    "# If 2D analysis type, Choose projection type (mean intensity or max intensity)\n",
    "# Mean intensity projection would be the equivalent of analyzing avg_intensity within the 3D volume\n",
    "projection_type = \"mean\" # \"mean\" or \"max\"\n",
    "\n",
    "# Stardist model name if nuclei labels predictions are present\n",
    "model_name = None\n",
    "\n",
    "# Iterate through the .czi and .nd2 files in the raw_data directory\n",
    "images = list_images(directory_path)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the channels you want to analyze using the following structure:\n",
    "# markers = [(channel_name, channel_nr, min_max_range),(..., ...)]\n",
    "# Remember in Python one starts counting from 0, so your first channel will be 0\n",
    "# min_max range defines the pixel intensity range within which a cell is considered positive for a marker\n",
    "# i.e. markers = [(\"ARSA\", 0, (0, 65536)), (\"MBP\", 1, (0, 65536))]\n",
    "markers = [(\"ARSA\", 0, (110, 65536)), (\"MBP\", 1, (110, 65536))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'results\\nihanseb_organoid\\avg_int' folder created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 1.8 block11 slide3 ARSA MBP batch 2 40x\n",
      "Original Array shape: (3, 25, 7787, 12008)\n",
      "Compressed Array shape: (3, 25, 3894, 6004)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:14<02:10, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 1.8 block4 ARSA MBP batch 1 40x\n",
      "Original Array shape: (3, 24, 10797, 10797)\n",
      "Compressed Array shape: (3, 24, 5399, 5399)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:40<02:49, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 2.2 block2 ARSA MBP batch 1 40x\n",
      "Original Array shape: (3, 28, 11397, 11397)\n",
      "Compressed Array shape: (3, 28, 5699, 5699)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:14<03:11, 27.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 2.2 block7 ARSA MBP batch 2 40x\n",
      "Original Array shape: (3, 25, 12600, 11394)\n",
      "Compressed Array shape: (3, 25, 6300, 5697)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:49<03:01, 30.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 3.5 block2 ARSA MBP batch 2 40x\n",
      "Original Array shape: (3, 20, 7193, 9002)\n",
      "Compressed Array shape: (3, 20, 3597, 4501)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:01<01:57, 23.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 5.2 block2 ARSA MBP batch 1 40x\n",
      "Original Array shape: (3, 26, 8999, 8396)\n",
      "Compressed Array shape: (3, 26, 4500, 4198)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:18<01:25, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 5.2 block4 ARSA MBP batch 2 40x\n",
      "Original Array shape: (3, 28, 12593, 13799)\n",
      "Compressed Array shape: (3, 28, 6297, 6900)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [03:03<01:27, 29.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 6.3 block7 ARSA MBP batch 2 40x\n",
      "Original Array shape: (3, 22, 9605, 6591)\n",
      "Compressed Array shape: (3, 22, 4803, 3296)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [03:16<00:47, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 7.5 block13 ARSA MBP batch 1 40x\n",
      "Original Array shape: (3, 33, 9001, 7795)\n",
      "Compressed Array shape: (3, 33, 4501, 3898)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:35<00:22, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 7.5 block14 ARSA MBP batch 2 40x\n",
      "Original Array shape: (3, 22, 8398, 8398)\n",
      "Compressed Array shape: (3, 22, 4199, 4199)\n",
      "\n",
      "Analyzing ROI: Organoid\n",
      "Extracting avg_int for ARSA inside 2D_Organoid\n",
      "Extracting avg_int for MBP inside 2D_Organoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:48<00:00, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files concatenated and saved to results\\nihanseb_organoid\\avg_int\\BP_per_filename_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the experiment name from the data directory path\n",
    "experiment_id = directory_path.name\n",
    "\n",
    "# Create a 'results' folder in the root directory\n",
    "results_folder = Path(\"results\") / experiment_id / \"avg_int\"\n",
    "\n",
    "# Construct ROI and nuclei predictions paths from directory_path above\n",
    "roi_path = directory_path / \"ROIs\"\n",
    "# nuclei_preds_path =  directory_path / \"nuclei_preds\" / analysis_type / model_name\n",
    "\n",
    "# Check for presence of ROIs\n",
    "try:\n",
    "    roi_names = [folder.name for folder in roi_path.iterdir() if folder.is_dir()]\n",
    "\n",
    "except FileNotFoundError:\n",
    "    roi_names = [\"auto_generated_ROI\"]\n",
    "    print(\"No manually defined ROI found, generating ROI automatically...\")\n",
    "\n",
    "try:\n",
    "    os.makedirs(results_folder)\n",
    "    print(f\"'{results_folder}' folder created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"'{results_folder}' folder already exists.\")\n",
    "\n",
    "if analysis_type == \"3D\":\n",
    "    # Set projection_type variable to None\n",
    "    projection_type = None\n",
    "\n",
    "for image in tqdm (images):\n",
    "\n",
    "    # Read image, apply slicing if needed and return filename and img as a np array\n",
    "    img, filename = read_image(image, slicing_factor_xy, slicing_factor_z)\n",
    "\n",
    "    # Generate maximum or mean intensity projection\n",
    "    if projection_type == \"max\":\n",
    "        img_projection = np.max(img, axis=1)\n",
    "    elif projection_type == \"mean\":\n",
    "        img_projection = np.mean(img, axis=1)\n",
    "\n",
    "    for roi_name in roi_names:\n",
    "\n",
    "        print(f\"\\nAnalyzing ROI: {roi_name}\")\n",
    "\n",
    "        # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "        props_list = []\n",
    "\n",
    "        # Read the user defined ROIs, in case of missing ROI implement logic for automatic segmentation\n",
    "        try:\n",
    "            # Read previously defined ROIs\n",
    "            organoid_mask = tifffile.imread(roi_path / roi_name / f\"{filename}.tiff\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # Add logic to automatically generate an organoid mask\n",
    "            pass\n",
    "\n",
    "        # Resample the organoid ROI if input img and ROI shape differ\n",
    "        if organoid_mask.shape[-2:] != img.shape[-2:]:\n",
    "            roi_slicing_factor = organoid_mask.shape[-1] / img.shape[-1]\n",
    "            \n",
    "            if roi_slicing_factor > 1:\n",
    "                print(\"Slicing ROI to match input image shape\")\n",
    "                roi_slicing_factor = round(organoid_mask.shape[-1] / img.shape[-1])\n",
    "                organoid_mask = organoid_mask[::round(roi_slicing_factor), ::round(roi_slicing_factor)]\n",
    "        \n",
    "            elif roi_slicing_factor < 1:\n",
    "                print(\"Upsampling ROI to match input image shape\")\n",
    "                organoid_mask = resize(\n",
    "                    organoid_mask, img.shape[-2:], order=0, preserve_range=True, anti_aliasing=False\n",
    "                )\n",
    "\n",
    "        # If analysis type == \"3D\" extend ROI over the entire volume\n",
    "        if analysis_type == \"3D\":\n",
    "            # Extract the number of z-slices to extend the mask\n",
    "            slice_nr = img.shape[1]\n",
    "            # Extend the mask across the entire volume\n",
    "            organoid_mask = np.tile(organoid_mask, (slice_nr, 1, 1))\n",
    "            \n",
    "        if fill_holes:\n",
    "            # Close empty holes surrounded by True pixels\n",
    "            organoid_mask = binary_fill_holes(organoid_mask)\n",
    "\n",
    "        # Transform organoid mask into a label type without the need to perform connected components\n",
    "        organoid_mask = organoid_mask.astype(np.uint8)\n",
    "\n",
    "        # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "        props_list = []\n",
    "\n",
    "        # Create a dictionary containing all image descriptors\n",
    "        descriptor_dict = {\n",
    "                    \"filename\": filename,\n",
    "                    \"roi\": roi_name,\n",
    "                    \"fill_holes\": fill_holes,\n",
    "                    \"slicing_factor_xy\": slicing_factor_xy,\n",
    "                    \"analysis_type\": analysis_type,\n",
    "                    \"projection_type\": projection_type,\n",
    "                    }\n",
    "\n",
    "        for channel_name, ch_nr, min_max_range in markers:\n",
    "\n",
    "            print(f\"Extracting avg_int for {channel_name} inside {analysis_type}_{roi_name}\")\n",
    "\n",
    "            if analysis_type == \"2D\":\n",
    "                # Ignore pixel values below the min_range (set them to 0)\n",
    "                img_projection[ch_nr] = np.where(img_projection[ch_nr] > min_max_range[0], img_projection[ch_nr], 0)\n",
    "\n",
    "                # Ignore pixels whose value is equal or above the max_range\n",
    "                # ROI is modified to ignore said pixels (results in filtered organoid_mask)\n",
    "                filtered_organoid_mask = np.where(img_projection[ch_nr] <= min_max_range[1], organoid_mask, 0)\n",
    "\n",
    "                # Transform organoid mask into a label type without the need to perform connected components\n",
    "                filtered_organoid_mask = filtered_organoid_mask.astype(np.uint8)\n",
    "\n",
    "                # Extract intensity information from each marker channel\n",
    "                props = measure.regionprops_table(label_image=filtered_organoid_mask,\n",
    "                                        intensity_image=img_projection[ch_nr],\n",
    "                                        properties=[\"label\", \"area\", \"intensity_mean\"])\n",
    "                \n",
    "            elif analysis_type == \"3D\":\n",
    "                # Ignore pixel values below the min_range (set them to 0)\n",
    "                img[ch_nr] = np.where(img[ch_nr] > min_max_range[0], img[ch_nr], 0)\n",
    "\n",
    "                # Ignore pixels whose value is equal or above the max_range\n",
    "                # ROI is modified to ignore said pixels (results in filtered organoid_mask)\n",
    "                filtered_organoid_mask = np.where(img[ch_nr] <= min_max_range[1], organoid_mask, 0)\n",
    "\n",
    "                # Transform organoid mask into a label type without the need to perform connected components\n",
    "                filtered_organoid_mask = filtered_organoid_mask.astype(np.uint8)\n",
    "\n",
    "                # Extract intensity information from each marker channel\n",
    "                props = measure.regionprops_table(label_image=filtered_organoid_mask,\n",
    "                                        intensity_image=img[ch_nr],\n",
    "                                        properties=[\"label\", \"area\", \"intensity_mean\"])\n",
    "                            \n",
    "            # Convert to dataframe\n",
    "            props_df = pd.DataFrame(props)\n",
    "\n",
    "            # Rename intensity_mean column to indicate the specific image\n",
    "            props_df.rename(columns={\"intensity_mean\": f\"{channel_name}_avg_int\"}, inplace=True)\n",
    "\n",
    "            # Rename area column to indicate the specific image\n",
    "            props_df.rename(columns={\"area\": f\"{channel_name}_area\"}, inplace=True)\n",
    "\n",
    "            # Append each props_df to props_list\n",
    "            props_list.append(props_df)\n",
    "\n",
    "        # Initialize the df with the first df in the list\n",
    "        props_df = props_list[0]\n",
    "        # Start looping from the second df in the list\n",
    "        for df in props_list[1:]:\n",
    "            props_df = props_df.merge(df, on=(\"label\"))\n",
    "\n",
    "        # Add each key-value pair from descriptor_dict to props_df at the specified position\n",
    "        insertion_position = 0    \n",
    "        for key, value in descriptor_dict.items():\n",
    "            props_df.insert(insertion_position, key, value)\n",
    "            insertion_position += 1  # Increment position to maintain the order of keys in descriptor_dict\n",
    "\n",
    "        # Define the .csv path\n",
    "        csv_path = results_folder / f'{filename}_per_label_avg_int.csv'\n",
    "\n",
    "        # SAve to .csv\n",
    "        props_df.to_csv(csv_path)\n",
    "\n",
    "# Get all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(results_folder, \"*.csv\"))\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "all_dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrame to a new CSV file\n",
    "output_path = os.path.join(results_folder, \"BP_per_filename_summary.csv\")\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"All CSV files concatenated and saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
