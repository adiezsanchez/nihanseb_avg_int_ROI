{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: /device:GPU:0\n",
      "Device type: GPU\n",
      "GPU model: device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from utils import get_gpu_details, list_images, read_image\n",
    "\n",
    "get_gpu_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_data\\\\nihanseb_organoid\\\\MLD 1.8 block4 ARSA MBP batch 1 40x.nd2',\n",
       " 'raw_data\\\\nihanseb_organoid\\\\MLD 2.2 block7 MBP MAP2 slide 7 batch 2 40x.nd2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the path where your images are stored, you can use absolute or relative paths to point at other disk locations\n",
    "directory_path = Path(\"./raw_data/nihanseb_organoid\")\n",
    "\n",
    "# Image size reduction (downsampling) to improve processing times (slicing, not lossless compression)\n",
    "# Now, in addition to xy, you can downsample across your z-stack\n",
    "slicing_factor_xy = 2 # Use 2 or 4 for downsampling in xy (None for lossless)\n",
    "slicing_factor_z = None # Use 2 to select 1 out of every 2 z-slices\n",
    "\n",
    "# Define the nuclei and markers of interest channel order ('Remember in Python one starts counting from zero')\n",
    "nuclei_channel = 2\n",
    "\n",
    "# Fill holes inside the resulting organoid mask? Set to False if you want to keep the holes\n",
    "fill_holes = True\n",
    "\n",
    "# Analyze intensity within the 3D volume of the ROI, or perform a mean or max intensity projection of the marker channel (2D)\n",
    "analysis_type = \"2D\" #\"2D\" or \"3D\"\n",
    "\n",
    "# If 2D analysis type, Choose projection type (mean intensity or max intensity)\n",
    "# Mean intensity projection would be the equivalent of analyzing avg_intensity within the 3D volume\n",
    "projection_type = \"mean\" # \"mean\" or \"max\"\n",
    "\n",
    "# Stardist model name if nuclei labels predictions are present\n",
    "model_name = None\n",
    "\n",
    "# Iterate through the .czi and .nd2 files in the raw_data directory\n",
    "images = list_images(directory_path)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the channels you want to analyze using the following structure:\n",
    "# markers = [(channel_name, channel_nr, min_max_range),(..., ...)]\n",
    "# Remember in Python one starts counting from 0, so your first channel will be 0\n",
    "# min_max range defines the pixel intensity range within which a cell is considered positive for a marker\n",
    "# i.e. markers = [(\"ARSA\", 0, (0, 65536)), (\"MBP\", 1, (0, 65536))]\n",
    "markers = [(\"ARSA\", 0, (110, 65536)), (\"MBP\", 1, (110, 65536))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'results\\nihanseb_organoid\\avg_int' folder already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 1.8 block4 ARSA MBP batch 1 40x\n",
      "Original Array shape: (3, 24, 10797, 10797)\n",
      "Compressed Array shape: (3, 24, 5399, 5399)\n",
      "\n",
      "Analyzing ROI: organoid_sf4\n",
      "Upsampling ROI to match input image shape\n",
      "Extracting avg_int for ARSA inside 2D_organoid_sf4\n",
      "Extracting avg_int for MBP inside 2D_organoid_sf4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:17<00:17, 17.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: MLD 2.2 block7 MBP MAP2 slide 7 batch 2 40x\n",
      "Original Array shape: (3, 24, 10191, 12603)\n",
      "Compressed Array shape: (3, 24, 5096, 6302)\n",
      "\n",
      "Analyzing ROI: organoid_sf4\n",
      "Upsampling ROI to match input image shape\n",
      "Extracting avg_int for ARSA inside 2D_organoid_sf4\n",
      "Extracting avg_int for MBP inside 2D_organoid_sf4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:49<00:00, 24.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files concatenated and saved to results\\nihanseb_organoid\\avg_int\\BP_per_filename_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the experiment name from the data directory path\n",
    "experiment_id = directory_path.name\n",
    "\n",
    "# Create a 'results' folder in the root directory\n",
    "results_folder = Path(\"results\") / experiment_id / \"avg_int\"\n",
    "\n",
    "# Construct ROI and nuclei predictions paths from directory_path above\n",
    "roi_path = directory_path / \"ROIs\"\n",
    "# nuclei_preds_path =  directory_path / \"nuclei_preds\" / analysis_type / model_name\n",
    "\n",
    "# Check for presence of ROIs\n",
    "try:\n",
    "    roi_names = [folder.name for folder in roi_path.iterdir() if folder.is_dir()]\n",
    "\n",
    "except FileNotFoundError:\n",
    "    roi_names = [\"auto_generated_ROI\"]\n",
    "    print(\"No manually defined ROI found, generating ROI automatically...\")\n",
    "\n",
    "try:\n",
    "    os.makedirs(results_folder)\n",
    "    print(f\"'{results_folder}' folder created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"'{results_folder}' folder already exists.\")\n",
    "\n",
    "if analysis_type == \"3D\":\n",
    "    # Set projection_type variable to None\n",
    "    projection_type = None\n",
    "\n",
    "for image in tqdm (images):\n",
    "\n",
    "    # Read image, apply slicing if needed and return filename and img as a np array\n",
    "    img, filename = read_image(image, slicing_factor_xy, slicing_factor_z)\n",
    "\n",
    "    # Generate maximum or mean intensity projection\n",
    "    if projection_type == \"max\":\n",
    "        img_projection = np.max(img, axis=1)\n",
    "    elif projection_type == \"mean\":\n",
    "        img_projection = np.mean(img, axis=1)\n",
    "\n",
    "    for roi_name in roi_names:\n",
    "\n",
    "        print(f\"\\nAnalyzing ROI: {roi_name}\")\n",
    "\n",
    "        # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "        props_list = []\n",
    "\n",
    "        # Read the user defined ROIs, in case of missing ROI implement logic for automatic segmentation\n",
    "        try:\n",
    "            # Read previously defined ROIs\n",
    "            organoid_mask = tifffile.imread(roi_path / roi_name / f\"{filename}.tiff\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # Add logic to automatically generate an organoid mask\n",
    "            pass\n",
    "\n",
    "        # Resample the organoid ROI if input img and ROI shape differ\n",
    "        if organoid_mask.shape[-2:] != img.shape[-2:]:\n",
    "            roi_slicing_factor = organoid_mask.shape[-1] / img.shape[-1]\n",
    "            \n",
    "            if roi_slicing_factor > 1:\n",
    "                print(\"Slicing ROI to match input image shape\")\n",
    "                roi_slicing_factor = round(organoid_mask.shape[-1] / img.shape[-1])\n",
    "                organoid_mask = organoid_mask[::round(roi_slicing_factor), ::round(roi_slicing_factor)]\n",
    "        \n",
    "            elif roi_slicing_factor < 1:\n",
    "                print(\"Upsampling ROI to match input image shape\")\n",
    "                organoid_mask = resize(\n",
    "                    organoid_mask, img.shape[-2:], order=0, preserve_range=True, anti_aliasing=False\n",
    "                )\n",
    "\n",
    "        # If analysis type == \"3D\" extend ROI over the entire volume\n",
    "        if analysis_type == \"3D\":\n",
    "            # Extract the number of z-slices to extend the mask\n",
    "            slice_nr = img.shape[1]\n",
    "            # Extend the mask across the entire volume\n",
    "            organoid_mask = np.tile(organoid_mask, (slice_nr, 1, 1))\n",
    "            \n",
    "        if fill_holes:\n",
    "            # Close empty holes surrounded by True pixels\n",
    "            organoid_mask = binary_fill_holes(organoid_mask)\n",
    "\n",
    "        # Transform organoid mask into a label type without the need to perform connected components\n",
    "        organoid_mask = organoid_mask.astype(np.uint8)\n",
    "\n",
    "        # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "        props_list = []\n",
    "\n",
    "        # Create a dictionary containing all image descriptors\n",
    "        descriptor_dict = {\n",
    "                    \"filename\": filename,\n",
    "                    \"roi\": roi_name,\n",
    "                    \"fill_holes\": fill_holes,\n",
    "                    \"slicing_factor_xy\": slicing_factor_xy,\n",
    "                    \"analysis_type\": analysis_type,\n",
    "                    \"projection_type\": projection_type,\n",
    "                    }\n",
    "\n",
    "        for channel_name, ch_nr, min_max_range in markers:\n",
    "\n",
    "            print(f\"Extracting avg_int for {channel_name} inside {analysis_type}_{roi_name}\")\n",
    "\n",
    "            if analysis_type == \"2D\":\n",
    "                # Ignore pixel values below the min_range (set them to 0)\n",
    "                img_projection[ch_nr] = np.where(img_projection[ch_nr] > min_max_range[0], img_projection[ch_nr], 0)\n",
    "\n",
    "                # Ignore pixels whose value is equal or above the max_range\n",
    "                # ROI is modified to ignore said pixels (results in filtered organoid_mask)\n",
    "                filtered_organoid_mask = np.where(img_projection[ch_nr] <= min_max_range[1], organoid_mask, 0)\n",
    "\n",
    "                # Transform organoid mask into a label type without the need to perform connected components\n",
    "                filtered_organoid_mask = filtered_organoid_mask.astype(np.uint8)\n",
    "\n",
    "                # Extract intensity information from each marker channel\n",
    "                props = measure.regionprops_table(label_image=filtered_organoid_mask,\n",
    "                                        intensity_image=img_projection[ch_nr],\n",
    "                                        properties=[\"label\", \"area\", \"intensity_mean\"])\n",
    "                \n",
    "            elif analysis_type == \"3D\":\n",
    "                # Ignore pixel values below the min_range (set them to 0)\n",
    "                img[ch_nr] = np.where(img[ch_nr] > min_max_range[0], img[ch_nr], 0)\n",
    "\n",
    "                # Ignore pixels whose value is equal or above the max_range\n",
    "                # ROI is modified to ignore said pixels (results in filtered organoid_mask)\n",
    "                filtered_organoid_mask = np.where(img[ch_nr] <= min_max_range[1], organoid_mask, 0)\n",
    "\n",
    "                # Transform organoid mask into a label type without the need to perform connected components\n",
    "                filtered_organoid_mask = filtered_organoid_mask.astype(np.uint8)\n",
    "\n",
    "                # Extract intensity information from each marker channel\n",
    "                props = measure.regionprops_table(label_image=filtered_organoid_mask,\n",
    "                                        intensity_image=img[ch_nr],\n",
    "                                        properties=[\"label\", \"area\", \"intensity_mean\"])\n",
    "                            \n",
    "            # Convert to dataframe\n",
    "            props_df = pd.DataFrame(props)\n",
    "\n",
    "            # Rename intensity_mean column to indicate the specific image\n",
    "            props_df.rename(columns={\"intensity_mean\": f\"{channel_name}_avg_int\"}, inplace=True)\n",
    "\n",
    "            # Append each props_df to props_list\n",
    "            props_list.append(props_df)\n",
    "\n",
    "        # Initialize the df with the first df in the list\n",
    "        props_df = props_list[0]\n",
    "        # Start looping from the second df in the list\n",
    "        for df in props_list[1:]:\n",
    "            props_df = props_df.merge(df, on=(\"label\",\"area\"))\n",
    "\n",
    "        # Add each key-value pair from descriptor_dict to props_df at the specified position\n",
    "        insertion_position = 0    \n",
    "        for key, value in descriptor_dict.items():\n",
    "            props_df.insert(insertion_position, key, value)\n",
    "            insertion_position += 1  # Increment position to maintain the order of keys in descriptor_dict\n",
    "\n",
    "        # Sort by area in descending order\n",
    "        props_df = props_df.sort_values(by='area', ascending=False)\n",
    "\n",
    "        # Define the .csv path\n",
    "        csv_path = results_folder / f'{filename}_per_label_avg_int.csv'\n",
    "\n",
    "        # SAve to .csv\n",
    "        props_df.to_csv(csv_path)\n",
    "\n",
    "# Get all CSV files in the folder\n",
    "csv_files = glob.glob(os.path.join(results_folder, \"*.csv\"))\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "all_dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrame to a new CSV file\n",
    "output_path = os.path.join(results_folder, \"BP_per_filename_summary.csv\")\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"All CSV files concatenated and saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
